<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Exercises in Macroeconometrics - 1&nbsp; Bayesian Estimation of Linear Regression Model</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./regression_exercises.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bayesian Estimation of Linear Regression Model</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Exercises in Macroeconometrics</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Simple Linear Regression</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bayesian Estimation of Linear Regression Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression_exercises.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Exercises in Bayesian Estimation of Autoregression</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-model" id="toc-the-model" class="nav-link active" data-scroll-target="#the-model"> <span class="header-section-number">1.1</span> The model</a></li>
  <li><a href="#likelihood-function" id="toc-likelihood-function" class="nav-link" data-scroll-target="#likelihood-function"> <span class="header-section-number">1.2</span> Likelihood function</a></li>
  <li><a href="#a-natural-conjugate-prior-distribution" id="toc-a-natural-conjugate-prior-distribution" class="nav-link" data-scroll-target="#a-natural-conjugate-prior-distribution"> <span class="header-section-number">1.3</span> A natural-conjugate prior distribution</a></li>
  <li><a href="#joint-posterior-distribution" id="toc-joint-posterior-distribution" class="nav-link" data-scroll-target="#joint-posterior-distribution"> <span class="header-section-number">1.4</span> Joint posterior distribution</a></li>
  <li><a href="#a-conditionally-conjugate-prior-distribution" id="toc-a-conditionally-conjugate-prior-distribution" class="nav-link" data-scroll-target="#a-conditionally-conjugate-prior-distribution"> <span class="header-section-number">1.5</span> A conditionally-conjugate prior distribution</a></li>
  <li><a href="#full-conditional-posterior-distributions" id="toc-full-conditional-posterior-distributions" class="nav-link" data-scroll-target="#full-conditional-posterior-distributions"> <span class="header-section-number">1.6</span> Full conditional posterior distributions</a></li>
  <li><a href="#gibbs-sampler" id="toc-gibbs-sampler" class="nav-link" data-scroll-target="#gibbs-sampler"> <span class="header-section-number">1.7</span> Gibbs sampler</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Bayesian Estimation of Linear Regression Model</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<blockquote class="blockquote">
<p>This part presents the derivations of the posterior distributions for a simple linear regression model. It considers cases of a natural-conjugate and conditionally-conjugate prior distributions and presents the analytical derivations of the joint posterior distribution for the former, the Gibbs sampler for the latter case.</p>
</blockquote>
<section id="the-model" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="the-model"><span class="header-section-number">1.1</span> The model</h2>
<p>Consider the following linear regression model: <span class="math display">\[\begin{align}
Y &amp;= \beta X + E\\
E|X &amp;\sim\mathcal{N}\left(\mathbf{0}_T, \sigma^2I_T\right),
\end{align}\]</span> where <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are <span class="math inline">\(T\times1\)</span> vectors of observations on the dependent and explanatory variables respectively, and <span class="math inline">\(T\)</span> is the sample size, <span class="math inline">\(E\)</span> is a <span class="math inline">\(T\times1\)</span> vector stacking the error terms, and <span class="math inline">\(\beta\)</span> is a scalar parameter. Conditionally on <span class="math inline">\(X\)</span>, <span class="math inline">\(E\)</span> is normally distributed with the mean set to a <span class="math inline">\(T\)</span>-column vector of zeros, denoted by <span class="math inline">\(\mathbf{0}_T\)</span>, and covariance matrix equal to <span class="math inline">\(\sigma^2I_T\)</span>, where <span class="math inline">\(\sigma^2\)</span> is individual error term variance, and <span class="math inline">\(I_T\)</span> is an identity matrix of order <span class="math inline">\(T\)</span>.The predictive density of data conditional of the explanatory variables and the parameters of the model that is implied by the model equations above is specified as: <span class="math display">\[\begin{equation}
Y|X,\beta,\sigma^2 \sim\mathcal{N}\left(\beta X, \sigma^2I_T\right).
\end{equation}\]</span></p>
</section>
<section id="likelihood-function" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="likelihood-function"><span class="header-section-number">1.2</span> Likelihood function</h2>
<p>Let vector <span class="math inline">\(\theta=\left(\beta,\sigma^2\right)'\)</span> collect the parameters of the model. Then, the likelihood function takes the following form: <span class="math display">\[\begin{equation}
L\left(\theta|Y,X\right) = (2\pi)^{-\frac{T}{2}} \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}(Y-\beta X)'(Y-\beta X) \right\}
\end{equation}\]</span> We show that the likelihood function has the form of a normal inverse gamma 2 distribution for the parameters of the model <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>. <span class="math display">\[\begin{align}
L\left(\theta|Y,X\right) &amp;\propto \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}(Y-\beta X)'(Y-\beta X) \right\}\\[1ex]
&amp;= \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}(Y-\hat\beta X +\hat\beta X - \beta X)'(Y-\hat\beta X +\hat\beta X-\beta X) \right\}\label{eq:likeli1}\\[1ex]
&amp;= \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}\left[ (\beta - \hat\beta)'X'X (\beta - \hat\beta) + (Y-\hat\beta X)'(Y-\hat\beta X)\right] \right\}\label{eq:likeli2}\\[1ex]
&amp;= \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2} (\beta - \hat\beta)'X'X (\beta - \hat\beta) \right\} \exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}  (Y-\hat\beta X)'(Y-\hat\beta X) \right\}\label{eq:likeli3}
\end{align}\]</span> where in the second line above we add and subtract <span class="math inline">\(\hat\beta X\)</span>, where <span class="math inline">\(\hat\beta = (X'X)^{-1}X'Y\)</span> is the Maximum Likelihood Estimator of <span class="math inline">\(\beta\)</span>, and then, simply regroup and cancel out appropriate elements to go from line <span class="math inline">\(\eqref{eq:likeli1}\)</span> to <span class="math inline">\(\eqref{eq:likeli2}\)</span>.</p>
<p>The outcome of the derivation is the kernel of the normal inverse gamma 2 distribution. To see this, reorder the terms in equation <span class="math inline">\(\eqref{eq:likeli3}\)</span> the following way: <span class="math display">\[\begin{equation}
\underbrace{\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2} (\beta - \hat\beta)'X'X (\beta - \hat\beta) \right\}}_{\text{normal part for }\beta|\sigma^2}
\underbrace{\left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}  (Y-\hat\beta X)'(Y-\hat\beta X) \right\}}_{\text{inverse gamma 2 part for }\sigma^2},
\end{equation}\]</span> and note that two parts can be easily identified. One is the kernel of the normal distribution of <span class="math inline">\(\beta\)</span> given <span class="math inline">\(\sigma^2\)</span>, and the other is the kernel of the inverse gamma 2 distribution for <span class="math inline">\(\sigma^2\)</span>.</p>
<p>We can, therefore, write that the likelihood function implies the following distribution for the parameters of the model: <span class="math display">\[\begin{equation}
L\left(\theta|Y,X\right) = \mathcal{NIG}2_{(N=1)}\left(\hat\beta, (X'X)^{-1}, (Y-\hat\beta X)'(Y-\hat\beta X),  T-3 \right)
\end{equation}\]</span></p>
</section>
<section id="a-natural-conjugate-prior-distribution" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="a-natural-conjugate-prior-distribution"><span class="header-section-number">1.3</span> A natural-conjugate prior distribution</h2>
<p>A natural-conjugate prior distribution is of the same form as the distribution of the parameters implied by the likelihood function. More importantly, it implies the joint posterior distribution in a form of the same parametric distribution, which is shown in Section <span class="math inline">\(\ref{sec:posterior}\)</span>. The naturally-conjugate prior distribution for parameters <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> is of normal inverse gamma 2 form. More specifically, it is specified by a normal conditional distribution of <span class="math inline">\(\beta\)</span> given <span class="math inline">\(\sigma^2\)</span> and a marginal inverse gamma 2 prior distribution for <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[\begin{align}
p\left(\beta, \sigma^2\right) &amp;= p\left(\beta|\sigma^2\right)p\left(\sigma^2\right),
\end{align}\]</span> where the individual distributions are as follows: <span class="math display">\[\begin{align}
p\left(\beta|\sigma^2\right)&amp;=\mathcal{N}\left( \underline{\beta}, \sigma^2\underline{\sigma}_{\beta}^2 \right)\\
p\left(\sigma^2\right)&amp;=\mathcal{IG}2(\underline{s},\underline{\nu}).
\end{align}\]</span> Therefore, we write down its kernel as: <span class="math display">\[\begin{equation}\label{eq:prior}
\mathcal{NIG}2_{(N=1)}\left(\underline{\beta}, \underline{\sigma}_{\beta}^2, \underline{s},\underline{\nu} \right) \propto \left(\sigma^2\right)^{-\frac{\underline{\nu}+3}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}\frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \right\}
\exp\left\{ -\frac{1}{2}\frac{\underline{s}}{\sigma^2} \right\}
\end{equation}\]</span></p>
</section>
<section id="joint-posterior-distribution" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="joint-posterior-distribution"><span class="header-section-number">1.4</span> Joint posterior distribution</h2>
<p>In this section, we derive an analytical solution to the joint posterior distribution of a simple regression model with natural-conjugate prior distribution in a form of the normal inverse gamma 2 distribution.</p>
<p>The posterior distribution is proportional to the product of the likelihood function and the prior distribution: <span class="math display">\[\begin{align}
p\left( \beta,\sigma^2|Y,X \right) &amp;\propto L\left( Y|X,\beta,\sigma^2 \right)p\left( \beta,\sigma^2 \right)\\
&amp;= L\left( Y|X,\beta,\sigma^2 \right)p\left( \beta|\sigma^2 \right)p\left( \sigma^2 \right)
\end{align}\]</span> We plug in the corresponding expressions for the likelihood function from equation <span class="math inline">\(\eqref{eq:likeli3}\)</span> and the prior distribution from equation <span class="math inline">\(\eqref{eq:prior}\)</span> to obtain: <span class="math display">\[\begin{align}
p\left( \beta,\sigma^2|Y,X \right) &amp;\propto
\left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2} (\beta - \hat\beta)'X'X (\beta - \hat\beta) \right\}\\
&amp;\qquad\times  \exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}  (Y-\hat\beta X)'(Y-\hat\beta X) \right\}\\
&amp;\qquad\times \left(\sigma^2\right)^{-\frac{\underline{\nu}+3}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}\frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \right\}\\
&amp;\qquad\times
\exp\left\{ -\frac{1}{2}\frac{\underline{s}}{\sigma^2} \right\}
\end{align}\]</span> which, after collecting corresponding powers of <span class="math inline">\(\sigma^2\)</span> and arguments of the exponential function, can be written as: <span class="math display">\[\begin{align}\label{eq:post-kernel}
p\left( \beta,\sigma^2|Y,X \right) \propto
\left( \sigma^2 \right)^{-\frac{\underline{\nu}+T+3}{2}}&amp;\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}
\left[ \frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) + (\beta - \hat\beta)'X'X (\beta - \hat\beta)\right.\right.\\
&amp;\qquad\left.\left.+ \underline{s} + (Y-\hat\beta X)'(Y-\hat\beta X) \right] \right\}
\end{align}\]</span></p>
<p>To derive the parameters of the posterior distribution we will now focus on expression in square parentheses in the exponential function. The idea is to derive the following quadratic form, <span class="math inline">\(\overline{\sigma}_{\beta}^{-2}(\beta-\overline{\beta})'(\beta-\overline{\beta})\)</span> and separate it from the rest of the elements. The derivation of the quadratic form requires completing the squares. The quadratic form will be used to construct the normal distribution part of the posterior distribution, whereas the remaining elements will be used to construct its inverse gamma 2 part.</p>
<p>The first step is to multiply all of the elements: <span class="math display">\[\begin{multline}
\frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) + (\beta - \hat\beta)'X'X (\beta - \hat\beta) + \underline{s} + (Y-\hat\beta X)'(Y-\hat\beta X)\\
= \beta^2\underline{\sigma}_{\beta}^{-2} - \beta 2 \underline{\beta} \underline{\sigma}_{\beta}^{-2} + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2}+ \beta^2X'X - \beta 2 \hat\beta X'X + \hat\beta^2 X'X + \underline{s} + Y'Y -2\hat\beta X'Y + \hat\beta^2 X'X
\end{multline}\]</span> The second step is to collect the elements containing <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\beta^2\)</span> to obtain: <span class="math display">\[\begin{equation}
= \beta^2\left( \underline{\sigma}_{\beta}^{-2} + X'X\right) - \beta 2 \left( \underline{\beta} \underline{\sigma}_{\beta}^{-2} + \hat\beta X'X \right) + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2}  + \underline{s} + Y'Y -2\hat\beta X'Y + 2\hat\beta^2 X'X
\end{equation}\]</span> It is easy to show that the last two elements in the formula above, <span class="math inline">\(-2\hat\beta X'Y + 2\hat\beta^2 X'X\)</span>, cancel out.</p>
<p>Let <span class="math inline">\(\overline{\sigma}_{\beta}^{-2} = \left( \underline{\sigma}_{\beta}^{-2} + X'X\right)\)</span>. Now, plug in <span class="math inline">\(\overline{\sigma}_{\beta}^{-2}\)</span> in the expression above and also multiply and divide its second element by <span class="math inline">\(\overline{\sigma}_{\beta}^{2}\)</span>: <span class="math display">\[\begin{equation}
= \beta^2\overline{\sigma}_{\beta}^{-2} - \beta 2 \left( \underline{\beta} \underline{\sigma}_{\beta}^{-2} + \hat\beta X'X \right)\overline{\sigma}_{\beta}^{2}\overline{\sigma}_{\beta}^{-2} + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2}  + \underline{s} + Y'Y
\end{equation}\]</span> Let <span class="math inline">\(\overline{\beta} = \left( \underline{\beta} \underline{\sigma}_{\beta}^{-2} + \hat\beta X'X \right)\overline{\sigma}_{\beta}^{2}\)</span>. In the next step, plug in <span class="math inline">\(\overline{\beta}\)</span> in the expression above and also add and subtract term <span class="math inline">\(\overline{\beta}^2 \overline{\sigma}_{\beta}^{-2}\)</span> to obtain: <span class="math display">\[\begin{equation}
= \beta^2\overline{\sigma}_{\beta}^{-2} - \beta 2 \overline{\beta}\overline{\sigma}_{\beta}^{-2} + \overline{\beta}^2 \overline{\sigma}_{\beta}^{-2} - \overline{\beta}^2 \overline{\sigma}_{\beta}^{-2} + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2}  + \underline{s} + Y'Y
\end{equation}\]</span> Note that the first three terms in above can be written as <span class="math inline">\(\beta^2\overline{\sigma}_{\beta}^{-2} - \beta 2 \overline{\beta}\overline{\sigma}_{\beta}^{-2} + \overline{\beta}^2 \overline{\sigma}_{\beta}^{-2} = \overline{\sigma}_{\beta}^{-2}\left(\beta-\overline{\beta}\right)'\left(\beta-\overline{\beta}\right)\)</span>.</p>
<p>Therefore, we conclude our derivation and obtain: <span class="math display">\[\begin{equation}
= \overline{\sigma}_{\beta}^{-2}\left(\beta-\overline{\beta}\right)'\left(\beta-\overline{\beta}\right) + \underline{s} + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2} - \overline{\beta}^2 \overline{\sigma}_{\beta}^{-2}  + Y'Y
\end{equation}\]</span> After plugging in the expression above back to the density function of the posterior distribution in equation <span class="math inline">\(\eqref{eq:post-kernel}\)</span> we obtain: <span class="math display">\[\begin{align}
p\left( \beta,\sigma^2|Y,X \right) &amp;\propto
\left( \sigma^2 \right)^{-\frac{\underline{\nu}+T+3}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}
\frac{1}{\overline{\sigma}_{\beta}^{2}}\left(\beta-\overline{\beta}\right)'\left(\beta-\overline{\beta}\right) \right\}\\
&amp;\qquad\times \exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2} \left( \underline{s} + \underline{\beta}^2 \underline{\sigma}_{\beta}^{-2} - \overline{\beta}^2 \overline{\sigma}_{\beta}^{-2}  + Y'Y  \right)  \right\}\\
&amp;=  \left(\sigma^2\right)^{-\frac{\overline{\nu}+3}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}\frac{1}{\overline{\sigma}_{\beta}^2}\left(\beta-\overline{\beta}\right)'\left(\beta-\overline{\beta}\right) \right\}\\
&amp;\qquad\times\exp\left\{ -\frac{1}{2}\frac{\overline{s}}{\sigma^2} \right\}
\end{align}\]</span> which fully defines the joint posterior distribution as the normal inverse gamma 2 distribution with parameters <span class="math inline">\(\overline{\beta}\)</span>, <span class="math inline">\(\overline{\sigma}_{\beta}^2\)</span>, <span class="math inline">\(\overline{s}\)</span>, and <span class="math inline">\(\overline{\nu}\)</span> given by: <span class="math display">\[\begin{align*}
p\left( \beta,\sigma^2|Y,X \right) &amp;= \mathcal{NIG}2_{(N=1)}\left(\overline{\beta}, \overline{\sigma}_{\beta}^2, \overline{s},\overline{\nu} \right)\\[1ex]
\overline{\sigma}_{\beta}^2 &amp;= \left( \underline{\sigma}_{\beta}^{-2} + X'X \right)^{-1} \\
\overline{\beta} &amp;= \overline{\sigma}_{\beta}^2\left( \underline{\sigma}_{\beta}^{-2}\underline{\beta} + X'Y \right) \\
\overline{s} &amp;= \underline{s} + \underline{\sigma}_{\beta}^{-2}\underline{\beta}^2 - \overline{\sigma}_{\beta}^{-2}\overline{\beta}^2 + Y'Y \\
\overline{\nu} &amp;= \underline{\nu} + T
\end{align*}\]</span> The distribution above fully characterizes our knowledge about the parameters of the model after updating the prior distribution with the information from the data.</p>
</section>
<section id="a-conditionally-conjugate-prior-distribution" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="a-conditionally-conjugate-prior-distribution"><span class="header-section-number">1.5</span> A conditionally-conjugate prior distribution</h2>
<p>In the subsequent two sections, we consider an alternative way of setting the prior distribution that leads to an alternative estimation procedure.</p>
<p>A conditionally-conjugate prior distribution implies the corresponding full conditional posterior distribution in the same functional form. To assure this property, we assume that <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> are independent and that the parameters follow the following independent normal inverse gamma 2 distribution. <span class="math display">\[\begin{align}
p\left(\beta, \sigma^2\right) &amp;= p\left(\beta\right)p\left(\sigma^2\right)\\[1ex]
p\left(\beta\right)&amp;=\mathcal{N}\left( \underline{\beta}, \underline{\sigma}_{\beta}^2 \right)\\
p\left(\sigma^2\right)&amp;=\mathcal{IG}2(\underline{s},\underline{\nu})
\end{align}\]</span> Therefore, we write down its kernel as: <span class="math display">\[\begin{equation}
p\left(\beta, \sigma^2\right) \propto
\underbrace{\exp\left\{ -\frac{1}{2}\frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \right\}}_{\text{normal part for }\beta}
\times
\underbrace{\left(\sigma^2\right)^{-\frac{\underline{\nu}+2}{2}}
\exp\left\{ -\frac{1}{2}\frac{\underline{s}}{\sigma^2} \right\}}_{\text{inverse gamma part for }\sigma^2}
\end{equation}\]</span></p>
</section>
<section id="full-conditional-posterior-distributions" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="full-conditional-posterior-distributions"><span class="header-section-number">1.6</span> Full conditional posterior distributions</h2>
<p>The prior independence of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> implies an intractable form of the joint posterior distribution. However, the independent normal inverse gamma 2 distribution belongs to a class of conditionally-conjugate prior distributions and implies that the full conditional posterior distributions <span class="math inline">\(p\left(\beta|Y,X,\sigma^2\right)\)</span> and <span class="math inline">\(p\left(\sigma^2|Y,X,\beta\right)\)</span> are in a form of known distributions. We derive these distributions below and specify the Gibbs sampler using them.</p>
<p>In the first step, we derive the full conditional posterior distribution for <span class="math inline">\(beta\)</span> given, <span class="math inline">\(Y\)</span>, <span class="math inline">\(X\)</span>, and <span class="math inline">\(\sigma^2\)</span>, that is denoted by <span class="math inline">\(p\left(\beta|Y,X,\sigma^2\right)\)</span>. Conditioning on <span class="math inline">\(\sigma^2\)</span> implies that, for the sake of deriving the full conditional posterior distribution of <span class="math inline">\(\beta\)</span>, we treat it as non-random and, therefore, any elements that contain <span class="math inline">\(\sigma^2\)</span> that do not contain <span class="math inline">\(\beta\)</span> can be omitted when working with the kernel of <span class="math inline">\(p\left(\beta|Y,X,\sigma^2\right)\)</span>. <span class="math display">\[\begin{align}
p\left(\beta|Y,X,\sigma^2\right) &amp;\propto L\left(\beta,\sigma^2|Y,X\right)p\left(\beta\right)\\
&amp;= \exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}(Y-\beta X)'(Y-\beta X) \right\} \times
\exp\left\{ -\frac{1}{2}\frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \right\}\\
&amp;= \exp\left\{ -\frac{1}{2}\left[\frac{1}{\sigma^2}(Y-\beta X)'(Y-\beta X) + \frac{1}{\underline{\sigma}_{\beta}^2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \right]\right\}\label{eq:betafullcond}
\end{align}\]</span></p>
<p>Focus on the expression in square parentheses and transform it to a quadratic form <span class="math inline">\(\frac{1}{\overline{\sigma}_{\beta}^2}(\beta-\overline{\beta})'(\beta-\overline{\beta})\)</span>, where <span class="math inline">\(\overline{\beta}\)</span> and <span class="math inline">\(\overline{\sigma}_{\beta}^2\)</span> denote the parameters of the full conditional posterior distribution for <span class="math inline">\(\beta\)</span>.</p>
<p>In this step of the derivation, we multiply all of the elements and then rearrange them collecting elements containing <span class="math inline">\(\beta^2\)</span> and <span class="math inline">\(\beta\)</span> respectively dropping all others elements from the kernel of the distribution: <span class="math display">\[\begin{align}
\sigma^{-2}&amp;(Y-\beta X)'(Y-\beta X) + \underline{\sigma}_{\beta}^{-2}(\beta-\underline{\beta})'(\beta-\underline{\beta}) \\
&amp;= \sigma^{-2}Y'Y -\beta2X'Y\sigma^{-2} + \beta^2X'X\sigma^{-2} + \beta^2\underline{\sigma}_{\beta}^{-2} - \beta2\underline{\beta}\underline{\sigma}_{\beta}^{-2}+ \underline{\beta}^{2}\underline{\sigma}_{\beta}^{-2}\\
&amp;= \beta^2\left(X'X\sigma^{-2} + \underline{\sigma}_{\beta}^{-2}\right) - \beta2\left(X'Y\sigma^{-2} + \underline{\beta}\underline{\sigma}_{\beta}^{-2}\right) + \dots
\end{align}\]</span> Let <span class="math inline">\(\overline{\sigma}_{\beta}^2=\left(X'X\sigma^{-2} + \underline{\sigma}_{\beta}^{-2}\right)^{-1}\)</span>, and multiply and divide the second element on the right-hand side of the second line above by <span class="math inline">\(\overline{\sigma}_{\beta}^2\)</span> to obtain: <span class="math display">\[\begin{align}
\propto \beta^2\overline{\sigma}_{\beta}^{-2} - \beta2\left(X'Y\sigma^{-2} + \underline{\beta}\underline{\sigma}_{\beta}^{-2}\right)\overline{\sigma}_{\beta}^2 \overline{\sigma}_{\beta}^{-2}
&amp;= \beta^2\overline{\sigma}_{\beta}^{-2} - \beta2 \overline{\beta} \overline{\sigma}_{\beta}^{-2}\\
&amp;= \beta^2\overline{\sigma}_{\beta}^{-2} - \beta2 \overline{\beta} \overline{\sigma}_{\beta}^{-2} + \overline{\beta}^2\overline{\sigma}_{\beta}^{-2} + \dots
\end{align}\]</span> Note that on the right-hand side of the first line above we plugged in <span class="math inline">\(\overline{\beta} = \left(X'Y\sigma^{-2} + \underline{\beta}\underline{\sigma}_{\beta}^{-2}\right)\overline{\sigma}_{\beta}^2\)</span>, and in the second line we added and subtracted from the expression element <span class="math inline">\(\overline{\beta}^2\overline{\sigma}_{\beta}^{-2}\)</span>. Then, we dropped the element with the negative sign as we do not need it in the kernel of the distribution for <span class="math inline">\(\beta\)</span>. Finally, we obtain the required quadratic form: <span class="math display">\[\begin{equation}
\beta^2\overline{\sigma}_{\beta}^{-2} - \beta2 \overline{\beta} \overline{\sigma}_{\beta}^{-2} + \overline{\beta}^2\overline{\sigma}_{\beta}^{-2} = \overline{\sigma}_{\beta}^{-2}(\beta-\overline{\beta})'(\beta-\overline{\beta})
\end{equation}\]</span> which we now plug in back again to the expression in equation <span class="math inline">\(\eqref{eq:betafullcond}\)</span>: <span class="math display">\[\begin{equation}
p\left(\beta|Y,X,\sigma^2\right) \propto  \exp\left\{ -\frac{1}{2}\overline{\sigma}_{\beta}^{-2}(\beta-\overline{\beta})'(\beta-\overline{\beta})\right\}
\end{equation}\]</span> in which we recognize the kernel of a normal distribution.</p>
<p>Therefore, we the full conditional posterior distribution of <span class="math inline">\(\beta\)</span> is a normal distribution: <span class="math display">\[\begin{align}
p\left(\beta|Y,X,\sigma^2\right) &amp;=\mathcal{N}\left(\overline{\beta}, \overline{\sigma}_{\beta}^2\right)\\
\overline{\sigma}_{\beta}^2 &amp;= \left( \underline{\sigma}_{\beta}^{-2}+ \sigma^{-2}X'X \right)^{-1}\\
\overline{\beta} &amp;= \overline{\sigma}_{\beta}^2\left( \underline{\sigma}_{\beta}^{-2}\underline{\beta} + \sigma^{-2}X'Y \right)
\end{align}\]</span></p>
<p>In the second step of the derivations, we proceed similarly to derive the full conditional posterior distribution of <span class="math inline">\(\sigma^2\)</span> given <span class="math inline">\(Y\)</span>, <span class="math inline">\(X\)</span>, and <span class="math inline">\(\beta\)</span>, that is denoted by <span class="math inline">\(p\left(\sigma^2|Y,X,\beta\right)\)</span>. Conditioning on <span class="math inline">\(\beta\)</span> implies that, for the sake of deriving the full conditional posterior distribution of <span class="math inline">\(\sigma^2\)</span>, we treat it as non-random and, therefore, any elements that contain <span class="math inline">\(\beta\)</span> and do not contain <span class="math inline">\(\sigma^2\)</span> can be omitted when working with the kernel of <span class="math inline">\(p\left(\sigma^2|Y,X,\beta\right)\)</span>. <span class="math display">\[\begin{align}
p\left(\sigma^2|Y,X,\beta\right) &amp;\propto L\left(\beta,\sigma^2|Y,X\right)p\left(\sigma^2\right)\\
&amp;= \left( \sigma^2 \right)^{-\frac{T}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}(Y-\beta X)'(Y-\beta X) \right\} \times
\left(\sigma^2\right)^{-\frac{\underline{\nu}+2}{2}}\exp\left\{ -\frac{1}{2}\frac{\underline{s}}{\sigma^2} \right\}\\
&amp;= \left( \sigma^2 \right)^{-\frac{T+\underline{\nu}+2}{2}}\exp\left\{ -\frac{1}{2}\frac{1}{\sigma^2}\left[(Y-\beta X)'(Y-\beta X) + \underline{s} \right]\right\}\label{eq:fcsi1}\\
&amp;= \left( \sigma^2 \right)^{-\frac{\overline{\nu}+2}{2}}\exp\left\{ -\frac{1}{2}\frac{\overline{s}}{\sigma^2}\right\}\label{eq:fcsi2}
\end{align}\]</span> In line <span class="math inline">\(\eqref{eq:fcsi1}\)</span>, we rearranged the elements, and in line <span class="math inline">\(\eqref{eq:fcsi2}\)</span> expressions for <span class="math inline">\(\overline{\nu} = T+\underline{\nu}\)</span> and <span class="math inline">\(\overline{s} = (Y-\beta X)'(Y-\beta X) + \underline{s}\)</span> were plugged in. The final line specifies the kernel of the following inverse gamma 2 distribution: <span class="math display">\[\begin{align}
p\left(\sigma^2|Y,X,\beta\right) &amp;= \mathcal{IG}2\left( \overline{s}, \overline{\nu} \right)\\[1ex]
\overline{s} &amp;= \underline{s} + (Y-\beta X)'(Y-\beta X) \\
\overline{\nu} &amp;= \underline{\nu} +T
\end{align}\]</span></p>
</section>
<section id="gibbs-sampler" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="gibbs-sampler"><span class="header-section-number">1.7</span> Gibbs sampler</h2>
<p>The Gibbs sampler for the simple linear regression is given by the following algorithm:</p>
<p><strong>Initialize</strong> <span class="math inline">\(\sigma^2\)</span> at some positive value <span class="math inline">\(\sigma^{2(0)}\)</span><br>
<strong>At each iteration</strong> <span class="math inline">\(s\)</span>:</p>
<ol type="1">
<li><strong>Draw</strong> <span class="math inline">\(\beta^{(s)}\sim p\left(\beta|Y,X,\sigma^{2(s-1)}\right) = \mathcal{N}\left(\overline{\beta}, \overline{\sigma}_{\beta}^2\right)\)</span></li>
<li><strong>Draw</strong> <span class="math inline">\(\sigma^{2(s)}\sim p\left(\sigma^2|Y,\beta^{(s)}\right)=\mathcal{IG}2\left( \overline{s}, \overline{\nu} \right)\)</span></li>
</ol>
<p><strong>Repeat</strong> steps 1. and 2. <span class="math inline">\(S_1 + S_2\)</span> times<br>
<strong>Discard</strong> the first <span class="math inline">\(S_1\)</span> draws that allowed the algorithm to converge to the stationary posterior distribution<br>
<strong>Output</strong> is a sample of draws from the joint posterior distribution <span class="math inline">\(\left\{ \beta^{(s)}, \sigma^{2(s)} \right\}_{s=S_1+1}^{S_2}\)</span></p>
<p>The implementation of this Gibbs sampler in R requires a feasible random number generators from the normal and inverse gamma 2 distributions. To sample random numbers from the normal distribution, <span class="math inline">\(\mathcal{N}_1\left( \mu, \sigma^2 \right)\)</span>, use function available from the package that is uploaded to the memory by default upon opening R. To sample random numbers from a multivariate normal distribution, <span class="math inline">\(\mathcal{N}_N\left( \mu, \Sigma \right)\)</span>, use function from package . Sampling random numbers from the inverse gamma 2 distribution, <span class="math inline">\(\mathcal{IG}2\left( s, \nu \right)\)</span>, requires a two-step procedure. In the first step, draw a random number from <span class="math inline">\(\bar{s}\sim\chi^2(\nu)\)</span> using function . In the second step, return <span class="math inline">\(s/\bar{s}\)</span> as a draw from <span class="math inline">\(\mathcal{IG}2\left( s, \nu \right)\)</span>.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Welcome</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./regression_exercises.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Exercises in Bayesian Estimation of Autoregression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>